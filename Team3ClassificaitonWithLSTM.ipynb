{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [conda root]",
      "language": "python",
      "name": "conda-root-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.6"
    },
    "colab": {
      "name": "Team3ClassificationWithLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuTan9/CS256/blob/main/Team3ClassificaitonWithLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYVyLRKTONBE"
      },
      "source": [
        "## Milestone 2 Part A \n",
        "\n",
        "---\n",
        "\n",
        "The main goal of this milestone is to perform a classification with LSTM on the dataset assigned to your group.\n",
        "\n",
        "The outcome of this milestone is to design, implement, and refine a LSTM machine learning model using Keras' LSTM to predict a given gesture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gliu_55hONBK"
      },
      "source": [
        "The following pair of gesture datasets are assigned to \n",
        "\n",
        "(a) Turn left and turn right: Team #4\n",
        "\n",
        "b) Turn  and circle : Team #3\n",
        "\n",
        "c) Stop  and no : Team #2\n",
        "\n",
        "d) Hello  and abort : Team #1\n",
        "\n",
        "### Main tasks\n",
        "1) Prepare the polar angle dataset so that it is ready for Keras LSTM model\n",
        "\n",
        "1.1) Format and prepare the data and randomly split it into 80% for training and 20% for testing\n",
        "\n",
        "1.2) Prepare your training datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/train \n",
        "\n",
        "1.3) Prepare your testing datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/test \n",
        "\n",
        "2) Create a LSTM model with Keras\n",
        "\n",
        "2.1) Vary the number of LSTM and layers and comment on how this would affect the gesture classification rate\n",
        "\n",
        "2.2) Vary the dropout rate(s) to see how this would affect the gesture classification rate and the CPU time taken to execute the process.\n",
        "\n",
        "3) Repeat (1) - (2) with the polar angular velocity dataset\n",
        "\n",
        "4) Repeat (1) - (2) with both the polar angle and the polar angular velocity datasets\n",
        "\n",
        "5) Comment, with reasons, on (1)-(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQvEHrZFCvYp"
      },
      "source": [
        "**Please provide the online discussion forum info here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikemqyqSu_xQ"
      },
      "source": [
        "import os"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxY-BsXTGEUi",
        "outputId": "86a2ec35-c5f1-4b4c-8f78-48f6f98fec2c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq07GxCmLjiH"
      },
      "source": [
        "Everyone must put the copied folder in the exact path shown below so you collaborate and get graded easily.   \n",
        "**No project score will be given for not following this folder configuration**    \n",
        "(Our grader is *not reponsible to figure out your own* perferred Google *folder* configuration)   \n",
        "**Only LSTM using Keras should be used in this milestone**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM2o2IwXIQgY",
        "outputId": "8213b562-a422-4d74-c633-96f2a3537fdc"
      },
      "source": [
        "root_path = \"./drive/My Drive/CS256Project/data/data_for_lstm\"\n",
        "\n",
        "(os.path.exists(root_path)) #Checking if the data paths indeed exist and are valid."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJMH4qG1qqOa"
      },
      "source": [
        "- Import libraries and models needed for this work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJTN-_ZRqqOb"
      },
      "source": [
        "# lstm model\n",
        "# from numpy import mean\n",
        "# from numpy import std\n",
        "# from numpy import dstack\n",
        "# from numpy import load\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Masking\n",
        "from keras import backend\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import os"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8DlU-uvm-8V"
      },
      "source": [
        "## Prepare your X_train.txt, y_train.txt, X_test.txt, y_test.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkGYkeaEoBVb"
      },
      "source": [
        "## your code here\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Return a list of numpy objects where each object represents one video \n",
        "def load_files(gesture):\n",
        "  video = []\n",
        "  filenames = os.listdir(os.path.join(\"./drive/My Drive/CS256Project/data/gestures_basic_d2\", gesture))\n",
        "  for filename in filenames:\n",
        "    # print(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'].shape)\n",
        "    video.append(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'])\n",
        "    # break\n",
        "  return video\n",
        "\n",
        "\n",
        "def create_files(filepath):\n",
        "  dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "  return dataframe.values"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-XZF85yAhiY"
      },
      "source": [
        "# Helper Function to set MIN_NUM_FRAMES\n",
        "# Parameter is an array of string, i.e. ['circle', 'turn', ...]\n",
        "def get_min_frames(gestures):\n",
        "  min_frame = 0\n",
        "  for gesture in gestures:\n",
        "    tmp = load_files(gesture)\n",
        "    for video in tmp:\n",
        "      if len(video) > min_frame:\n",
        "        min_frame = len(video)\n",
        "  return min_frame\n",
        "\n",
        "#print(get_min_frames(['circle','turn']))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYbV80JyKxZ4"
      },
      "source": [
        "MIN_JOINT = 5\n",
        "MAX_JOINT = 10\n",
        "MIN_NUM_FRAMES = get_min_frames(['circle','turn']) #replace gestures if needed\n",
        "MASK_VALUE = -1000\n",
        "# Move the origin to nose\n",
        "def updateCoord(frame):\n",
        "  return frame - frame[0]\n",
        "\n",
        "\n",
        "def getPolar(frame):\n",
        "  tmp = []\n",
        "  for i in range(1, len(frame)):\n",
        "    tmp.append(np.arctan2(frame[i][1], frame[i][0]))\n",
        "  return tmp\n",
        "\n",
        "\n",
        "def getVelocity(polars):\n",
        "  # deprecated\n",
        "  # the second dimension is 6 since we're just keeping the hand movements, which there will be 6 joints in total\n",
        "  # Min_Joint and Max_Joint keep the indices of the joints we need\n",
        "  velocity = [[MASK_VALUE for _ in range(MAX_JOINT - MIN_JOINT + 1)] for _ in range(len(polars))] #pad with mask value\n",
        "  for frame in range(1, len(polars)):\n",
        "    for joint in range(MAX_JOINT - MIN_JOINT + 1):\n",
        "      velocity[frame][joint] = polars[frame][joint] - polars[frame-1][joint]\n",
        "  return velocity\n",
        "\n",
        "\n",
        "# Prepares features and target into the right format\n",
        "def read_polar(gesture0, gesture1):\n",
        "  X_0_raw = load_files(gesture0)\n",
        "  X_0 = []\n",
        "  for video in X_0_raw:\n",
        "    polar = []\n",
        "    for frame in range(len(video)):\n",
        "      coord = video[frame][1][0].transpose(1, 0)\n",
        "      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n",
        "    velocity = getVelocity(polar)\n",
        "    features = np.full((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2), MASK_VALUE, dtype='float32') #pad with 1000 which is not in [-2pi, 2pi]\n",
        "    features[:len(video), :, 0] = polar\n",
        "    features[:len(video), :, 1] = velocity\n",
        "    X_0.append(features)\n",
        "  y_0 = [0 for _ in range(len(X_0))]\n",
        "\n",
        "  X_1_raw = load_files(gesture1)\n",
        "  X_1 = []\n",
        "  for video in X_1_raw:\n",
        "    polar = []\n",
        "    for frame in range(len(video)):\n",
        "      coord = video[frame][1][0].transpose(1, 0)\n",
        "      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n",
        "    velocity = getVelocity(polar)\n",
        "    features = np.full((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2), MASK_VALUE, dtype='float32') #pad\n",
        "    features[:len(video), :, 0] = polar\n",
        "    features[:len(video), :, 1] = velocity\n",
        "    X_1.append(features)\n",
        "  y_1 = [1 for _ in range(len(X_1))]\n",
        "\n",
        "  return np.array(X_0 + X_1, dtype = object), np.array(y_0 + y_1)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBPlqcHCLLRs"
      },
      "source": [
        "X, y = read_polar('turn', 'circle')\n",
        "# X will be storing m videos, each with n frames, while each frames have 17 joints\n",
        "# y will be an array looking like [[0] * j, [1] * k] where j is the number of first gesture and k will be the number of second gesture"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AGUXYP_LhMT"
      },
      "source": [
        "# Prepares traning and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI7e2w0gFJp0",
        "outputId": "18be209c-3a39-4601-a41c-ee5aa1c3180e"
      },
      "source": [
        "np.array(X_train, dtype=object).shape, np.array(X_test, dtype=object).shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((98, 72, 6, 2), (25, 72, 6, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8dmO0r-FLzm",
        "outputId": "5e495ccf-4047-427c-8349-c35eb181ae8e"
      },
      "source": [
        "len(y_train), len(y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqVzmlpaFXyP"
      },
      "source": [
        "- You may modify the code below for you specific project needs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CaVh9ARRrV5"
      },
      "source": [
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy, neurons=50, drop_out_rate = 0.5, lstm_layers = 1, dropout_layers = 1, summary = True):\n",
        "\tverbose, epochs, batch_size = 0, 15, 64\n",
        "\ttrainX = trainX.astype('float32')\n",
        "\ttestX = testX.astype('float32')\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], 2\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Masking(mask_value=MASK_VALUE, input_shape=(n_timesteps, n_features))) # Masking layer\n",
        "\tfor _ in range(lstm_layers - 1):\n",
        "\t\tmodel.add(LSTM(neurons, input_length=trainX.shape[1], input_dim=trainX.shape[2], return_sequences = True))\n",
        "\tmodel.add(LSTM(neurons, input_length=trainX.shape[1], input_dim=trainX.shape[2]))\n",
        " \n",
        "\tfor _ in range(dropout_layers):\n",
        "\t\tmodel.add(Dropout(drop_out_rate))\n",
        "\t\tmodel.add(Dense(100, activation='relu'))\n",
        "\t\n",
        "\tmodel.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  \n",
        "\t# fit network\n",
        "\tif(summary):\n",
        "\t\tmodel.summary()\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# model.fit(trainX, trainy)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n",
        "\treturn accuracy"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eYmRtxRGF_O",
        "outputId": "e71f1fc5-67a1-45d6-bf74-522a05523080"
      },
      "source": [
        "# Clears backend keras session: https://stackoverflow.com/questions/55299510/cpu-usage-and-time-until-training-starts-increasing-on-each-model-fit-in-keras/55300684\n",
        "backend.clear_session()\n",
        "\n",
        "print('+-----------+')\n",
        "print('|Polar angle|')\n",
        "print('+-----------+')\n",
        "Polar_train, Polar_test = X_train[:, :, :, 0], X_test[:, :, :, 0]\n",
        "plot_num_neurons, accuracy = [], []\n",
        "for neurons in range(50, 1001, 50):\n",
        "  plot_num_neurons.append(neurons)\n",
        "  backend.clear_session()\n",
        "  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = 1, summary = False)\n",
        "  accuracy.append(acc)\n",
        "  # print('\\t{0} neurons have accuracy {1:.2f}'.format(neurons, acc))\n",
        "\n",
        "plt.subplot(1, 4, 1) # row 1, col 2 index 1\n",
        "plt.plot(plot_num_neurons, accuracy)\n",
        "plt.xlabel('Number of neurons')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "\n",
        "plot_dropout, accuracy = [], []\n",
        "for dropout_rate in np.arange(0.0, 1.0, 0.1):\n",
        "  plot_dropout.append(dropout_rate)\n",
        "  backend.clear_session()\n",
        "  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = dropout_rate, lstm_layers= 1, dropout_layers = 1, summary = False)\n",
        "  accuracy.append(acc)\n",
        "\n",
        "plt.subplot(1, 4, 2) # index 2\n",
        "plt.plot(plot_dropout, accuracy)\n",
        "plt.xlabel('Dropout rate')\n",
        "\n",
        "plot_LSTM, accuracy = [], []\n",
        "for layers in np.arange(1, 6, 1):\n",
        "  plot_LSTM.append(layers)\n",
        "  backend.clear_session()\n",
        "  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n",
        "  accuracy.append(acc)\n",
        "  \n",
        "plt.subplot(1, 4, 3) # index 3\n",
        "plt.plot(plot_LSTM, accuracy)\n",
        "plt.xlabel('LSTM layers')\n",
        "\n",
        "plot_dropout_layer, accuracy = [], []\n",
        "for layers in np.arange(1, 6, 1):\n",
        "  plot_dropout_layer.append(layers)\n",
        "  backend.clear_session()\n",
        "  # %%time\n",
        "  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = layers, summary = False)\n",
        "  accuracy.append(acc)\n",
        "\n",
        "plt.subplot(1, 4, 4) # index 4\n",
        "plt.plot(plot_dropout_layer, accuracy)\n",
        "plt.xlabel('Dropout layers')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+\n",
            "|Polar angle|\n",
            "+-----------+\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f82c024ccb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f82c47a6d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlQ_KXz1GO34"
      },
      "source": [
        "# commit: 'Changing #layer and #neuron'\n",
        "print('+-----------+')\n",
        "print('|Polar angle|')\n",
        "print('+-----------+')\n",
        "Polar_train, Polar_test = X_train[:, :, :, 0], X_test[:, :, :, 0]\n",
        "\n",
        "\n",
        "lstm = []\n",
        "layer_gen = range(1, 11)\n",
        "neuron_gen = range(50, 1001, 30)\n",
        "for layers in layer_gen:\n",
        "  row = []\n",
        "  print(layers, end = '')\n",
        "  for neurons in tqdm(neuron_gen):\n",
        "    backend.clear_session()\n",
        "    acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n",
        "    row.append(acc)\n",
        "  lstm.append(row)\n",
        "\n",
        "plt.figure(figsize=(30, 10))\n",
        "sns.heatmap(lstm, linewidth=0.5, xticklabels= [i for i in neuron_gen], yticklabels=[i for i in layer_gen], annot = True)\n",
        "plt.xlabel('Neurons')\n",
        "plt.ylabel('Layers')\n",
        "plt.title('LSTM layer')\n",
        "plt.savefig('./drive/My Drive/CS256Project/LSTM_layer_heatmap-20211114.png')\n",
        "np.savetxt(\"./drive/My Drive/CS256Project/LSTM_layer-20211114.csv\", lstm, delimiter=\",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEmtiq8jGWsD"
      },
      "source": [
        "backend.clear_session()\n",
        "print('+--------+')\n",
        "print('|Velocity|')\n",
        "print('+--------+')\n",
        "Velocity_train, Velocity_test = X_train[:, :, :, 1], X_test[:, :, :, 1]\n",
        "plot_num_neurons, accuracy = [], []\n",
        "for neurons in range(30, 110, 10):\n",
        "  plot_num_neurons.append(neurons)\n",
        "  backend.clear_session()\n",
        "  acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = 1, summary = False)\n",
        "  accuracy.append(acc)\n",
        "  print('\\t{0} neurons have accuracy {1:.2f}'.format(neurons, acc))\n",
        "\n",
        "plt.subplot(1, 4, 1) # row 1, col 2 index 1\n",
        "plt.plot(plot_num_neurons, accuracy)\n",
        "plt.xlabel('Number of neurons')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "# Goes with 40 neurons for now \n",
        "# plot_LSTM, accuracy = [], []\n",
        "# for layers in np.arange(1, 6, 1):\n",
        "#   plot_LSTM.append(layers)\n",
        "#   backend.clear_session()\n",
        "#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n",
        "#   accuracy.append(acc)\n",
        "#   print('\\t{0} layers have accuracy {1:.2f}'.format(layers, acc))\n",
        "\n",
        "# plt.subplot(1, 4, 3) # index 3\n",
        "# plt.plot(plot_LSTM, accuracy)\n",
        "# plt.xlabel('LSTM layers')\n",
        "\n",
        "# plot_dropout_layer, accuracy = [], []\n",
        "# for layers in np.arange(1, 6, 1):\n",
        "#   plot_dropout_layer.append(layers)\n",
        "#   backend.clear_session()\n",
        "#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = 0.5, lstm_layers= 4, dropout_layers = layers, summary = False)\n",
        "#   accuracy.append(acc)\n",
        "#   print('\\t{0} dense layers have accuracy {1:.2f}'.format(layers, acc))\n",
        "\n",
        "# plt.subplot(1, 4, 4) # index 2\n",
        "# plt.plot(plot_dropout_layer, accuracy)\n",
        "# plt.xlabel('Dropout layers')\n",
        "\n",
        "# plot_dropout, accuracy = [], []\n",
        "# for dropout_rate in np.arange(0.0, 1.1, 0.1):\n",
        "#   plot_dropout.append(dropout_rate)\n",
        "#   %%time\n",
        "#   backend.clear_session()\n",
        "#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = dropout_rate, lstm_layers= 4, dropout_layers = 1, summary = False)\n",
        "#   accuracy.append(acc)\n",
        "#   print('\\t{0} dropout rate have accuracy {1:.2f}'.format(dropout_rate, acc))\n",
        "\n",
        "\n",
        "# plt.subplot(1, 4, 2) # index 2\n",
        "# plt.plot(plot_dropout, accuracy)\n",
        "# plt.xlabel('Dropout rate')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1zDMrazGd7i"
      },
      "source": [
        "#############\n",
        "#SAMPLE CODE#\n",
        "#############\n",
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n",
        "# run an experiment\n",
        "def run_experiment(max_lstm=1001):\n",
        "\t# load data\n",
        "\ttrainX, trainy, testX, testy = load_dataset(prefix=root_path)\n",
        "\t# repeat experiment\n",
        "\tscores = list()\n",
        "\tfor r in range(100,max_lstm,100):\n",
        "\t\tscore = evaluate_model(trainX, trainy, testX, testy,max_lstm)\n",
        "\t\tscore = score * 100.0\n",
        "\t\tprint('> with %d LSTMs: %.3f' % (r, score))\n",
        "\t\tscores.append(score)\n",
        "\t# summarize results\n",
        "\tsummarize_results(scores)\n",
        " %%time\n",
        "# run the experiment\n",
        "run_experiment()\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset(prefix=''):\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint('[samples, time steps, features]',trainX.shape, trainy.shape, '[samples, time steps, features]',testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy\n",
        "  # load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_group(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\tprint('filenames:', filenames)\n",
        "  # print('filenames shape:', filenames.shape)\n",
        "\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}