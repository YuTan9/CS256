{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"Team3ClassificaitonWithLSTM.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/YuTan9/CS256/blob/main/Team3ClassificaitonWithLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"bYVyLRKTONBE"},"source":["## Milestone 2 Part A \n","\n","---\n","\n","The main goal of this milestone is to perform a classification with LSTM on the dataset assigned to your group.\n","\n","The outcome of this milestone is to design, implement, and refine a LSTM machine learning model using Keras' LSTM to predict a given gesture."]},{"cell_type":"markdown","metadata":{"id":"gliu_55hONBK"},"source":["The following pair of gesture datasets are assigned to \n","\n","(a) Turn left and turn right: Team #4\n","\n","b) Turn  and circle : Team #3\n","\n","c) Stop  and no : Team #2\n","\n","d) Hello  and abort : Team #1\n","\n","### Main tasks\n","1) Prepare the polar angle dataset so that it is ready for Keras LSTM model\n","\n","1.1) Format and prepare the data and randomly split it into 80% for training and 20% for testing\n","\n","1.2) Prepare your training datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/train \n","\n","1.3) Prepare your testing datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/test \n","\n","2) Create a LSTM model with Keras\n","\n","2.1) Vary the number of LSTM and layers and comment on how this would affect the gesture classification rate\n","\n","2.2) Vary the dropout rate(s) to see how this would affect the gesture classification rate and the CPU time taken to execute the process.\n","\n","3) Repeat (1) - (2) with the polar angular velocity dataset\n","\n","4) Repeat (1) - (2) with both the polar angle and the polar angular velocity datasets\n","\n","5) Comment, with reasons, on (1)-(4)\n"]},{"cell_type":"markdown","metadata":{"id":"nQvEHrZFCvYp"},"source":["**Please provide the online discussion forum info here**"]},{"cell_type":"code","metadata":{"id":"ikemqyqSu_xQ","executionInfo":{"status":"ok","timestamp":1637109358554,"user_tz":480,"elapsed":6,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["import os"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxY-BsXTGEUi","executionInfo":{"status":"ok","timestamp":1637109397283,"user_tz":480,"elapsed":21059,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"f1fb2771-5f70-4427-b1c7-3d1139db326a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"xq07GxCmLjiH"},"source":["Everyone must put the copied folder in the exact path shown below so you collaborate and get graded easily.   \n","**No project score will be given for not following this folder configuration**    \n","(Our grader is *not reponsible to figure out your own* perferred Google *folder* configuration)   \n","**Only LSTM using Keras should be used in this milestone**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KM2o2IwXIQgY","executionInfo":{"status":"ok","timestamp":1637109399776,"user_tz":480,"elapsed":986,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"20211941-e021-4644-8e8a-ebd30f600671"},"source":["root_path = \"./drive/My Drive/CS256Project/data/data_for_lstm\"\n","\n","(os.path.exists(root_path)) #Checking if the data paths indeed exist and are valid."],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"IJMH4qG1qqOa"},"source":["- Import libraries and models needed for this work"]},{"cell_type":"code","metadata":{"id":"SJTN-_ZRqqOb","executionInfo":{"status":"ok","timestamp":1637109403999,"user_tz":480,"elapsed":3245,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["# lstm model\n","# from numpy import mean\n","# from numpy import std\n","# from numpy import dstack\n","# from numpy import load\n","import numpy as np\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import Masking\n","from keras import backend\n","from keras.utils.np_utils import to_categorical\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","import os"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I8DlU-uvm-8V"},"source":["## Prepare your X_train.txt, y_train.txt, X_test.txt, y_test.txt"]},{"cell_type":"code","metadata":{"id":"MkGYkeaEoBVb","executionInfo":{"status":"ok","timestamp":1637109405439,"user_tz":480,"elapsed":333,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["## your code here\n","from sklearn.model_selection import train_test_split\n","\n","# Return a list of numpy objects where each object represents one video \n","def load_files(gesture):\n","  video = []\n","  filenames = os.listdir(os.path.join(\"./drive/My Drive/CS256Project/data/gestures_basic_d2\", gesture))\n","  for filename in filenames:\n","    # print(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'].shape)\n","    video.append(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'])\n","    # break\n","  return video\n","\n","\n","def create_files(filepath):\n","  dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n","  return dataframe.values"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-XZF85yAhiY","executionInfo":{"status":"ok","timestamp":1637109407516,"user_tz":480,"elapsed":318,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["# Helper Function to set MIN_NUM_FRAMES\n","# Parameter is an array of string, i.e. ['circle', 'turn', ...]\n","def get_min_frames(gestures):\n","  min_frame = 0\n","  for gesture in gestures:\n","    tmp = load_files(gesture)\n","    for video in tmp:\n","      if len(video) > min_frame:\n","        min_frame = len(video)\n","  return min_frame\n","\n","#print(get_min_frames(['circle','turn']))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"sYbV80JyKxZ4","executionInfo":{"status":"ok","timestamp":1637109521576,"user_tz":480,"elapsed":67219,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["MIN_JOINT = 5\n","MAX_JOINT = 10\n","MIN_NUM_FRAMES = get_min_frames(['circle','turn']) #replace gestures if needed\n","MASK_VALUE = -1000\n","# Move the origin to nose\n","def updateCoord(frame):\n","  return frame - frame[0]\n","\n","\n","def getPolar(frame):\n","  tmp = []\n","  for i in range(1, len(frame)):\n","    tmp.append(np.arctan2(frame[i][1], frame[i][0]))\n","  return tmp\n","\n","\n","def getVelocity(polars):\n","  # deprecated\n","  # the second dimension is 6 since we're just keeping the hand movements, which there will be 6 joints in total\n","  # Min_Joint and Max_Joint keep the indices of the joints we need\n","  velocity = [[MASK_VALUE for _ in range(MAX_JOINT - MIN_JOINT + 1)] for _ in range(len(polars))] #pad with mask value\n","  for frame in range(1, len(polars)):\n","    for joint in range(MAX_JOINT - MIN_JOINT + 1):\n","      velocity[frame][joint] = polars[frame][joint] - polars[frame-1][joint]\n","  return velocity\n","\n","\n","# Prepares features and target into the right format\n","def read_polar(gesture0, gesture1):\n","  X_0_raw = load_files(gesture0)\n","  X_0 = []\n","  for video in X_0_raw:\n","    polar = []\n","    for frame in range(len(video)):\n","      coord = video[frame][1][0].transpose(1, 0)\n","      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n","    velocity = getVelocity(polar)\n","    features = np.full((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2), MASK_VALUE, dtype='float32') #pad with 1000 which is not in [-2pi, 2pi]\n","    features[:len(video), :, 0] = polar\n","    features[:len(video), :, 1] = velocity\n","    X_0.append(features)\n","  y_0 = [0 for _ in range(len(X_0))]\n","\n","  X_1_raw = load_files(gesture1)\n","  X_1 = []\n","  for video in X_1_raw:\n","    polar = []\n","    for frame in range(len(video)):\n","      coord = video[frame][1][0].transpose(1, 0)\n","      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n","    velocity = getVelocity(polar)\n","    features = np.full((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2), MASK_VALUE, dtype='float32') #pad\n","    features[:len(video), :, 0] = polar\n","    features[:len(video), :, 1] = velocity\n","    X_1.append(features)\n","  y_1 = [1 for _ in range(len(X_1))]\n","\n","  return np.array(X_0 + X_1, dtype = 'float32'), np.array(y_0 + y_1)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBPlqcHCLLRs","executionInfo":{"status":"ok","timestamp":1637109577085,"user_tz":480,"elapsed":1131,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["X, y = read_polar('turn', 'circle')\n","# X will be storing m videos, each with n frames, while each frames have 17 joints\n","# y will be an array looking like [[0] * j, [1] * k] where j is the number of first gesture and k will be the number of second gesture"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AGUXYP_LhMT","executionInfo":{"status":"ok","timestamp":1637109579232,"user_tz":480,"elapsed":6,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["# Prepares traning and testing datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nI7e2w0gFJp0","executionInfo":{"status":"ok","timestamp":1637109641911,"user_tz":480,"elapsed":553,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"ca98556c-4a56-4de4-df6c-0f9d28f68e1a"},"source":["np.array(X_train, dtype='float32').shape, np.array(X_test, dtype='float32').shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((98, 72, 6, 2), (25, 72, 6, 2))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8dmO0r-FLzm","executionInfo":{"status":"ok","timestamp":1637109645385,"user_tz":480,"elapsed":420,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"e23e1622-05cc-4dba-a975-f87a68238918"},"source":["len(y_train), len(y_test)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(98, 25)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"pC3lcLMmUZY_","executionInfo":{"status":"ok","timestamp":1637109646636,"user_tz":480,"elapsed":4,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["# reshapes them to 2D\n","X_train_2D = np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, X_train.shape), indexing=\"xy\"))) + [X_train.ravel()])\n","X_test_2D = np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, X_test.shape), indexing=\"xy\"))) + [X_test.ravel()])"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"-JiLb0sQUaHY","executionInfo":{"status":"ok","timestamp":1637109673401,"user_tz":480,"elapsed":443,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}}},"source":["import pandas as pd\n","\n","# Converts all datasets to panda dataframes\n","\n","# X train\n","X_train_dataframe = pd.DataFrame(X_train_2D, columns=['video_id', 'frame_id', 'joint', 'polar', 'value'])\n","X_train_dataframe['polar'] = ['angle' if x == 0 else 'velocity' for x in X_train_dataframe['polar']]\n","X_train_dataframe = X_train_dataframe.astype({'video_id': int, 'frame_id': int, 'joint': int})\n","\n","# X test\n","X_test_dataframe = pd.DataFrame(X_test_2D, columns=['video_id', 'frame_id', 'joint', 'polar', 'value'])\n","X_test_dataframe['polar'] = ['angle' if x == 0 else 'velocity' for x in X_test_dataframe['polar']]\n","X_test_dataframe = X_test_dataframe.astype({'video_id': int, 'frame_id': int, 'joint': int})\n","\n","y_train_dataframe = pd.DataFrame(y_train, columns=['gesture'])\n","y_test_dataframe = pd.DataFrame(y_test, columns=['gesture'])"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"2hDt8DWfUfHQ","executionInfo":{"status":"ok","timestamp":1637109675393,"user_tz":480,"elapsed":23,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"77a91574-f00b-4308-af65-0243fc7cc024"},"source":["X_train_dataframe.head(6)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>video_id</th>\n","      <th>frame_id</th>\n","      <th>joint</th>\n","      <th>polar</th>\n","      <th>value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>angle</td>\n","      <td>2.290420</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>velocity</td>\n","      <td>-1000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>angle</td>\n","      <td>1.169995</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>velocity</td>\n","      <td>-1000.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>angle</td>\n","      <td>2.139944</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>velocity</td>\n","      <td>-1000.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   video_id  frame_id  joint     polar        value\n","0         0         0      0     angle     2.290420\n","1         0         0      0  velocity -1000.000000\n","2         0         0      1     angle     1.169995\n","3         0         0      1  velocity -1000.000000\n","4         0         0      2     angle     2.139944\n","5         0         0      2  velocity -1000.000000"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":137,"output_embedded_package_id":"19Yst9OvTwESqDF3H93zK2Evzv8Lgm4_A"},"id":"0-_NKwmKUhCj","executionInfo":{"status":"ok","timestamp":1637109685516,"user_tz":480,"elapsed":7818,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"f6a89217-be15-451b-ff4e-989d21afa327"},"source":["import json\n","\n","# Converts dataframes to JSON\n","X_train_JSON = X_train_dataframe.to_json(orient=\"index\")\n","X_test_JSON = X_test_dataframe.to_json(orient=\"index\")\n","y_train_JSON = y_train_dataframe.to_json(orient=\"index\")\n","y_test_JSON = y_test_dataframe.to_json(orient=\"index\")\n","\n","json.dumps(json.loads(X_train_JSON))"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"wqVzmlpaFXyP"},"source":["- You may modify the code below for you specific project needs"]},{"cell_type":"code","metadata":{"id":"3CaVh9ARRrV5"},"source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy, neurons=50, drop_out_rate = 0.5, lstm_layers = 1, dropout_layers = 1, summary = True):\n","\tverbose, epochs, batch_size = 0, 15, 64\n","\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], 2\n","\tmodel = Sequential()\n","\tmodel.add(Masking(mask_value=MASK_VALUE, input_shape=(n_timesteps, n_features))) # Masking layer\n","\tfor _ in range(lstm_layers - 1):\n","\t\tmodel.add(LSTM(neurons, input_length=trainX.shape[1], input_dim=trainX.shape[2], return_sequences = True))\n","\tmodel.add(LSTM(neurons, input_length=trainX.shape[1], input_dim=trainX.shape[2]))\n"," \n","\tfor _ in range(dropout_layers):\n","\t\tmodel.add(Dropout(drop_out_rate))\n","\t\tmodel.add(Dense(100, activation='relu'))\n","\t\n","\tmodel.add(Dense(n_outputs, activation='softmax'))\n","\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","\t# fit network\n","\tif(summary):\n","\t\tmodel.summary()\n","\ttrainy = to_categorical(trainy)\n","\ttesty = to_categorical(testy)\n","\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","\t# model.fit(trainX, trainy)\n","\t# evaluate model\n","\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n","\treturn accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1eYmRtxRGF_O","outputId":"e71f1fc5-67a1-45d6-bf74-522a05523080"},"source":["# Clears backend keras session: https://stackoverflow.com/questions/55299510/cpu-usage-and-time-until-training-starts-increasing-on-each-model-fit-in-keras/55300684\n","backend.clear_session()\n","\n","print('+-----------+')\n","print('|Polar angle|')\n","print('+-----------+')\n","Polar_train, Polar_test = X_train[:, :, :, 0], X_test[:, :, :, 0]\n","plot_num_neurons, accuracy = [], []\n","for neurons in range(50, 1001, 50):\n","  plot_num_neurons.append(neurons)\n","  backend.clear_session()\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","  # print('\\t{0} neurons have accuracy {1:.2f}'.format(neurons, acc))\n","\n","plt.subplot(1, 4, 1) # row 1, col 2 index 1\n","plt.plot(plot_num_neurons, accuracy)\n","plt.xlabel('Number of neurons')\n","plt.ylabel('Accuracy')\n","\n","\n","plot_dropout, accuracy = [], []\n","for dropout_rate in np.arange(0.0, 1.0, 0.1):\n","  plot_dropout.append(dropout_rate)\n","  backend.clear_session()\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = dropout_rate, lstm_layers= 1, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","\n","plt.subplot(1, 4, 2) # index 2\n","plt.plot(plot_dropout, accuracy)\n","plt.xlabel('Dropout rate')\n","\n","plot_LSTM, accuracy = [], []\n","for layers in np.arange(1, 6, 1):\n","  plot_LSTM.append(layers)\n","  backend.clear_session()\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","  \n","plt.subplot(1, 4, 3) # index 3\n","plt.plot(plot_LSTM, accuracy)\n","plt.xlabel('LSTM layers')\n","\n","plot_dropout_layer, accuracy = [], []\n","for layers in np.arange(1, 6, 1):\n","  plot_dropout_layer.append(layers)\n","  backend.clear_session()\n","  # %%time\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = layers, summary = False)\n","  accuracy.append(acc)\n","\n","plt.subplot(1, 4, 4) # index 4\n","plt.plot(plot_dropout_layer, accuracy)\n","plt.xlabel('Dropout layers')\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["+-----------+\n","|Polar angle|\n","+-----------+\n","WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f82c024ccb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f82c47a6d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}]},{"cell_type":"code","metadata":{"id":"GlQ_KXz1GO34"},"source":["# commit: 'Changing #layer and #neuron'\n","print('+-----------+')\n","print('|Polar angle|')\n","print('+-----------+')\n","Polar_train, Polar_test = X_train[:, :, :, 0], X_test[:, :, :, 0]\n","\n","\n","lstm = []\n","layer_gen = range(1, 11)\n","neuron_gen = range(50, 1001, 30)\n","for layers in layer_gen:\n","  row = []\n","  print(layers, end = '')\n","  for neurons in tqdm(neuron_gen):\n","    backend.clear_session()\n","    acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n","    row.append(acc)\n","  lstm.append(row)\n","\n","plt.figure(figsize=(30, 10))\n","sns.heatmap(lstm, linewidth=0.5, xticklabels= [i for i in neuron_gen], yticklabels=[i for i in layer_gen], annot = True)\n","plt.xlabel('Neurons')\n","plt.ylabel('Layers')\n","plt.title('LSTM layer')\n","plt.savefig('./drive/My Drive/CS256Project/LSTM_layer_heatmap-20211114.png')\n","np.savetxt(\"./drive/My Drive/CS256Project/LSTM_layer-20211114.csv\", lstm, delimiter=\",\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bEmtiq8jGWsD"},"source":["backend.clear_session()\n","print('+--------+')\n","print('|Velocity|')\n","print('+--------+')\n","Velocity_train, Velocity_test = X_train[:, :, :, 1], X_test[:, :, :, 1]\n","plot_num_neurons, accuracy = [], []\n","for neurons in range(30, 110, 10):\n","  plot_num_neurons.append(neurons)\n","  backend.clear_session()\n","  acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","  print('\\t{0} neurons have accuracy {1:.2f}'.format(neurons, acc))\n","\n","plt.subplot(1, 4, 1) # row 1, col 2 index 1\n","plt.plot(plot_num_neurons, accuracy)\n","plt.xlabel('Number of neurons')\n","plt.ylabel('Accuracy')\n","\n","# Goes with 40 neurons for now \n","# plot_LSTM, accuracy = [], []\n","# for layers in np.arange(1, 6, 1):\n","#   plot_LSTM.append(layers)\n","#   backend.clear_session()\n","#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n","#   accuracy.append(acc)\n","#   print('\\t{0} layers have accuracy {1:.2f}'.format(layers, acc))\n","\n","# plt.subplot(1, 4, 3) # index 3\n","# plt.plot(plot_LSTM, accuracy)\n","# plt.xlabel('LSTM layers')\n","\n","# plot_dropout_layer, accuracy = [], []\n","# for layers in np.arange(1, 6, 1):\n","#   plot_dropout_layer.append(layers)\n","#   backend.clear_session()\n","#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = 0.5, lstm_layers= 4, dropout_layers = layers, summary = False)\n","#   accuracy.append(acc)\n","#   print('\\t{0} dense layers have accuracy {1:.2f}'.format(layers, acc))\n","\n","# plt.subplot(1, 4, 4) # index 2\n","# plt.plot(plot_dropout_layer, accuracy)\n","# plt.xlabel('Dropout layers')\n","\n","# plot_dropout, accuracy = [], []\n","# for dropout_rate in np.arange(0.0, 1.1, 0.1):\n","#   plot_dropout.append(dropout_rate)\n","#   %%time\n","#   backend.clear_session()\n","#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = dropout_rate, lstm_layers= 4, dropout_layers = 1, summary = False)\n","#   accuracy.append(acc)\n","#   print('\\t{0} dropout rate have accuracy {1:.2f}'.format(dropout_rate, acc))\n","\n","\n","# plt.subplot(1, 4, 2) # index 2\n","# plt.plot(plot_dropout, accuracy)\n","# plt.xlabel('Dropout rate')\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLSgPzR1iarP"},"source":["backend.clear_session()\n","print('+-------------------+')\n","print('|Angle and Velocity|')\n","print('+-------------------+')\n","\n","both_trainX = np.concatenate((X_train[:, :, :, 0], X_train[:, :, :, 1]), axis=2)\n","both_testX = np.concatenate((X_test[:, :, :, 0], X_test[:, :, :, 1]), axis=2)\n","both_trainX.shape\n","\n","plot_neurons, acc_neurons = [], []\n","plot_layers, acc_layers = [], []\n","plot_dropout, acc_dropout = [], []\n","# ----------------------------------------------------------------\n","# Different number of neurons\n","# ----------------------------------------------------------------\n","for neurons in np.arange(50, 1001, 50):\n","  acc_neurons.append(evaluate_model(both_trainX, y_train, both_testX, y_test, neurons=neurons, summary=False))\n","  plot_neurons.append(neurons)\n","plt.subplot(1, 4, 1) # row 1, col 2 index 1\n","#plt.figure(figsize=(8,4))\n","plt.plot(plot_neurons, acc_neurons)\n","plt.xlabel('Number of neurons')\n","plt.ylabel('Accuracy')\n","\n","backend.clear_session()\n","\n","\n","# ----------------------------------------------------------------\n","# Different number LSTM layers\n","# ----------------------------------------------------------------\n","\n","for layers in np.arange(1, 6, 1):\n","  acc_layers.append(evaluate_model(both_trainX, y_train, both_testX, y_test, lstm_layers=layers, summary=False))\n","  plot_layers.append(layers)\n","plt.subplot(1, 4, 2) # row 1, col 2 index 2\n","#plt.figure(figsize=(8,4))\n","plt.plot(plot_layers, acc_layers)\n","plt.xlabel('Number of layers')\n","plt.ylabel('Accuracy')\n","\n","backend.clear_session()\n","\n","# ----------------------------------------------------------------\n","# Different Dropout\n","# ----------------------------------------------------------------\n","\n","for rate in np.arange(0.0, 1.0 , 0.2):\n","  acc_dropout.append(evaluate_model(both_trainX, y_train, both_testX, y_test, drop_out_rate=rate, summary=False))\n","  plot_dropout.append(rate)\n","\n","plt.subplot(1, 4, 3) # row 1, col 2 index 3\n","#plt.figure(figsize=(8,4))\n","plt.plot(plot_dropout, acc_dropout)\n","plt.xlabel('Dropout rate')\n","plt.ylabel('Accuracy')\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1zDMrazGd7i"},"source":["#############\n","#SAMPLE CODE#\n","#############\n","# summarize scores\n","def summarize_results(scores):\n","\tprint(scores)\n","\tm, s = mean(scores), std(scores)\n","\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))\n","# run an experiment\n","def run_experiment(max_lstm=1001):\n","\t# load data\n","\ttrainX, trainy, testX, testy = load_dataset(prefix=root_path)\n","\t# repeat experiment\n","\tscores = list()\n","\tfor r in range(100,max_lstm,100):\n","\t\tscore = evaluate_model(trainX, trainy, testX, testy,max_lstm)\n","\t\tscore = score * 100.0\n","\t\tprint('> with %d LSTMs: %.3f' % (r, score))\n","\t\tscores.append(score)\n","\t# summarize results\n","\tsummarize_results(scores)\n"," %%time\n","# run the experiment\n","run_experiment()\n","# load the dataset, returns train and test X and y elements\n","def load_dataset(prefix=''):\n","\t# load all train\n","\ttrainX, trainy = load_dataset_group('train', prefix + 'HARDataset/')\n","\tprint(trainX.shape, trainy.shape)\n","\t# load all test\n","\ttestX, testy = load_dataset_group('test', prefix + 'HARDataset/')\n","\tprint(testX.shape, testy.shape)\n","\t# zero-offset class values\n","\ttrainy = trainy - 1\n","\ttesty = testy - 1\n","\t# one hot encode y\n","\ttrainy = to_categorical(trainy)\n","\ttesty = to_categorical(testy)\n","\tprint('[samples, time steps, features]',trainX.shape, trainy.shape, '[samples, time steps, features]',testX.shape, testy.shape)\n","\treturn trainX, trainy, testX, testy\n","  # load a single file as a numpy array\n","def load_file(filepath):\n","\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n","\treturn dataframe.values\n","# load a list of files and return as a 3d numpy array\n","def load_group(filenames, prefix=''):\n","\tloaded = list()\n","\tfor name in filenames:\n","\t\tdata = load_file(prefix + name)\n","\t\tloaded.append(data)\n","\t# stack group so that features are the 3rd dimension\n","\tloaded = dstack(loaded)\n","\treturn loaded\n","# load a dataset group, such as train or test\n","def load_dataset_group(group, prefix=''):\n","\tfilepath = prefix + group + '/Inertial Signals/'\n","\t# load all 9 files as a single array\n","\tfilenames = list()\n","\t# total acceleration\n","\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n","\t# body acceleration\n","\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n","\t# body gyroscope\n","\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n","\tprint('filenames:', filenames)\n","  # print('filenames shape:', filenames.shape)\n","\n","\t# load input data\n","\tX = load_group(filenames, filepath)\n","\t# load class output\n","\ty = load_file(prefix + group + '/y_'+group+'.txt')\n","\treturn X, y"],"execution_count":null,"outputs":[]}]}