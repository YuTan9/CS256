{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python [conda root]","language":"python","name":"conda-root-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"},"colab":{"name":"Team3ClassificaitonWithLSTM.ipynb","provenance":[],"collapsed_sections":["YHt_5WSFQ7DY"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"bYVyLRKTONBE"},"source":["## Milestone 2 Part A \n","\n","---\n","\n","The main goal of this milestone is to perform a classification with LSTM on the dataset assigned to your group.\n","\n","The outcome of this milestone is to design, implement, and refine a LSTM machine learning model using Keras' LSTM to predict a given gesture."]},{"cell_type":"markdown","metadata":{"id":"gliu_55hONBK"},"source":["The following pair of gesture datasets are assigned to \n","\n","(a) Turn left and turn right: Team #4\n","\n","b) Turn  and circle : Team #3\n","\n","c) Stop  and no : Team #2\n","\n","d) Hello  and abort : Team #1\n","\n","### Main tasks\n","1) Prepare the polar angle dataset so that it is ready for Keras LSTM model\n","\n","1.1) Format and prepare the data and randomly split it into 80% for training and 20% for testing\n","\n","1.2) Prepare your training datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/train \n","\n","1.3) Prepare your testing datasets, name them as X_train.txt and y_train.txt, and then put them under the data/data_for_lstm/test \n","\n","2) Create a LSTM model with Keras\n","\n","2.1) Vary the number of LSTM and layers and comment on how this would affect the gesture classification rate\n","\n","2.2) Vary the dropout rate(s) to see how this would affect the gesture classification rate and the CPU time taken to execute the process.\n","\n","3) Repeat (1) - (2) with the polar angular velocity dataset\n","\n","4) Repeat (1) - (2) with both the polar angle and the polar angular velocity datasets\n","\n","5) Comment, with reasons, on (1)-(4)\n"]},{"cell_type":"markdown","metadata":{"id":"nQvEHrZFCvYp"},"source":["**Please provide the online discussion forum info here**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uxY-BsXTGEUi","executionInfo":{"status":"ok","timestamp":1637125014629,"user_tz":480,"elapsed":19809,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}},"outputId":"d8fe772a-7678-4ea2-e179-eefb953cd684"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"xq07GxCmLjiH"},"source":["Everyone must put the copied folder in the exact path shown below so you collaborate and get graded easily.   \n","**No project score will be given for not following this folder configuration**    \n","(Our grader is *not reponsible to figure out your own* perferred Google *folder* configuration)   \n","**Only LSTM using Keras should be used in this milestone**"]},{"cell_type":"markdown","metadata":{"id":"IJMH4qG1qqOa"},"source":["- Import libraries and models needed for this work"]},{"cell_type":"code","metadata":{"id":"SJTN-_ZRqqOb","executionInfo":{"status":"ok","timestamp":1637125520013,"user_tz":480,"elapsed":163,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["import numpy as np\n","from pandas import read_csv\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import Masking\n","from keras import backend\n","from keras.utils.np_utils import to_categorical\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt \n","import seaborn as sns\n","import os\n","from sklearn.model_selection import train_test_split\n","import json"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YHt_5WSFQ7DY"},"source":["# Utility functions"]},{"cell_type":"code","metadata":{"id":"f-XZF85yAhiY","executionInfo":{"status":"ok","timestamp":1637125206316,"user_tz":480,"elapsed":134,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["# Helper Function to set MIN_NUM_FRAMES\n","# Parameter is an array of string, i.e. ['circle', 'turn', ...]\n","def get_min_frames(gestures):\n","  min_frame = 0\n","  for gesture in gestures:\n","    tmp = load_files(gesture)\n","    for video in tmp:\n","      if len(video) > min_frame:\n","        min_frame = len(video)\n","  return min_frame\n","\n","#print(get_min_frames(['circle','turn']))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzYoiB6JQsRr","executionInfo":{"status":"ok","timestamp":1637125208139,"user_tz":480,"elapsed":124,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["def load_files(gesture):\n","  video = []\n","  filenames = os.listdir(os.path.join(\"./drive/My Drive/CS256Project/data/gestures_basic_d2\", gesture))\n","  for filename in filenames:\n","    # print(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'].shape)\n","    video.append(np.load(os.path.join('./drive/My Drive/CS256Project/data/gestures_basic_d2',gesture, filename), allow_pickle=True)['keypoints'])\n","    # break\n","  return video"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZDQ-wLDQugv","executionInfo":{"status":"ok","timestamp":1637125209297,"user_tz":480,"elapsed":121,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["def create_files(filepath):\n","  dataframe = read_csv(filepath, header=None, delim_whitespace=True)\n","  return dataframe.values"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"ubB5LJk4QyYO","executionInfo":{"status":"ok","timestamp":1637125210450,"user_tz":480,"elapsed":2,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["def updateCoord(frame):\n","  return frame - frame[0]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"CT9brp7cQ0ZW","executionInfo":{"status":"ok","timestamp":1637125211980,"user_tz":480,"elapsed":130,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["def getPolar(frame):\n","  tmp = []\n","  for i in range(1, len(frame)):\n","    tmp.append(np.arctan2(frame[i][1], frame[i][0]))\n","  return tmp"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ph9w1d-NQ2Jy","executionInfo":{"status":"ok","timestamp":1637125213220,"user_tz":480,"elapsed":132,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["def getVelocity(polars):\n","  # deprecated\n","  # the second dimension is 6 since we're just keeping the hand movements, which there will be 6 joints in total\n","  # Min_Joint and Max_Joint keep the indices of the joints we need\n","  velocity = [[MASK_VALUE for _ in range(MAX_JOINT - MIN_JOINT + 1)] for _ in range(len(polars))] #pad with mask value\n","  for frame in range(1, len(polars)):\n","    for joint in range(MAX_JOINT - MIN_JOINT + 1):\n","      velocity[frame][joint] = polars[frame][joint] - polars[frame-1][joint]\n","  return velocity"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"xEE4Gy6UQ4vO","executionInfo":{"status":"ok","timestamp":1637125214538,"user_tz":480,"elapsed":121,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["# Prepares features and target into the right format\n","def read_polar(gesture0, gesture1):\n","  X_0_raw = load_files(gesture0)\n","  X_0 = []\n","  for video in X_0_raw:\n","    polar = []\n","    for frame in range(len(video)):\n","      coord = video[frame][1][0].transpose(1, 0)\n","      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n","    velocity = getVelocity(polar)\n","    features = np.full((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2), MASK_VALUE, dtype='float32') #pad with 1000 which is not in [-2pi, 2pi]\n","    features[:len(video), :, 0] = polar\n","    features[:len(video), :, 1] = velocity\n","    X_0.append(features)\n","  y_0 = [0 for _ in range(len(X_0))]\n","\n","  X_1_raw = load_files(gesture1)\n","  X_1 = []\n","  for video in X_1_raw:\n","    polar = []\n","    for frame in range(len(video)):\n","      coord = video[frame][1][0].transpose(1, 0)\n","      polar.append(getPolar(updateCoord(coord))[MIN_JOINT:MAX_JOINT+1])\n","    velocity = getVelocity(polar)\n","    features = np.full((MIN_NUM_FRAMES, MAX_JOINT - MIN_JOINT + 1, 2), MASK_VALUE, dtype='float32') #pad\n","    features[:len(video), :, 0] = polar\n","    features[:len(video), :, 1] = velocity\n","    X_1.append(features)\n","  y_1 = [1 for _ in range(len(X_1))]\n","\n","  return np.array(X_0 + X_1, dtype = 'float32'), np.array(y_0 + y_1)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hHSA85HKQ-_6"},"source":["# Global variables"]},{"cell_type":"code","metadata":{"id":"DKKWtjInQX0R","executionInfo":{"status":"ok","timestamp":1637125315411,"user_tz":480,"elapsed":481,"user":{"displayName":"Yu Tang Shen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdCMG8b3aJk_G66GP2EFIyLgHnZzR-5ARrZDaF=s64","userId":"00043457419726923717"}}},"source":["root_path = \"./drive/My Drive/CS256Project/data/data_for_lstm\"\n","# MIN_JOINT ~ MAX_JOINT defines what joints the model will focus on\n","MIN_JOINT = 5\n","MAX_JOINT = 10\n","MIN_NUM_FRAMES = get_min_frames(['circle','turn']) #replace gestures if needed\n","MASK_VALUE = -1000\n","assert (os.path.exists(root_path)) #Checking if the data paths indeed exist and are valid."],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I8DlU-uvm-8V"},"source":["# Prepare your X_train.txt, y_train.txt, X_test.txt, y_test.txt"]},{"cell_type":"code","metadata":{"id":"zBPlqcHCLLRs"},"source":["X, y = read_polar('turn', 'circle')\n","# X will be storing m videos, each with n frames, while each frames have 17 joints\n","# y will be an array looking like [[0] * j, [1] * k] where j is the number of first gesture and k will be the number of second gesture"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2AGUXYP_LhMT"},"source":["# Prepares traning and testing datasets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nI7e2w0gFJp0","executionInfo":{"status":"ok","timestamp":1637109641911,"user_tz":480,"elapsed":553,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"ca98556c-4a56-4de4-df6c-0f9d28f68e1a"},"source":["np.array(X_train, dtype='float32').shape, np.array(X_test, dtype='float32').shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((98, 72, 6, 2), (25, 72, 6, 2))"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S8dmO0r-FLzm","executionInfo":{"status":"ok","timestamp":1637109645385,"user_tz":480,"elapsed":420,"user":{"displayName":"Ivan Baradi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhgJjmChdQUYmiwbIc7Zl14l01Jy-ELibZIQTP=s64","userId":"10054649189296170335"}},"outputId":"e23e1622-05cc-4dba-a975-f87a68238918"},"source":["len(y_train), len(y_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(98, 25)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"-JiLb0sQUaHY"},"source":["# reshapes them to 2D\n","X_train_2D = np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, X_train.shape), indexing=\"xy\"))) + [X_train.ravel()])\n","X_test_2D = np.column_stack(list(map(np.ravel, np.meshgrid(*map(np.arange, X_test.shape), indexing=\"xy\"))) + [X_test.ravel()])\n","\n","# Converts all datasets to pandas dataframes\n","\n","# X train\n","X_train_dataframe = pd.DataFrame(X_train_2D, columns=['video_id', 'frame_id', 'joint', 'polar', 'value'])\n","X_train_dataframe['polar'] = ['angle' if x == 0 else 'velocity' for x in X_train_dataframe['polar']]\n","X_train_dataframe = X_train_dataframe.astype({'video_id': int, 'frame_id': int, 'joint': int})\n","\n","# X test\n","X_test_dataframe = pd.DataFrame(X_test_2D, columns=['video_id', 'frame_id', 'joint', 'polar', 'value'])\n","X_test_dataframe['polar'] = ['angle' if x == 0 else 'velocity' for x in X_test_dataframe['polar']]\n","X_test_dataframe = X_test_dataframe.astype({'video_id': int, 'frame_id': int, 'joint': int})\n","\n","y_train_dataframe = pd.DataFrame(y_train, columns=['gesture'])\n","y_test_dataframe = pd.DataFrame(y_test, columns=['gesture'])\n","\n","X_train_dataframe.head(6)\n","\n","# Converts dataframes to JSON\n","X_train_JSON = X_train_dataframe.to_json(orient=\"index\")\n","X_test_JSON = X_test_dataframe.to_json(orient=\"index\")\n","y_train_JSON = y_train_dataframe.to_json(orient=\"index\")\n","y_test_JSON = y_test_dataframe.to_json(orient=\"index\")\n","\n","json.dumps(json.loads(X_train_JSON))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EIgkOG4xS2zt"},"source":["## Another implementation"]},{"cell_type":"code","metadata":{"id":"y5nu0pVJSMGT"},"source":["def output_to_txt(folder = './drive/My Drive/CS256Project/data/data_for_lstm/'):\n","  X_train_output_filename = folder + 'train/X_train.txt'\n","  with open(X_train_output_filename, 'w', encoding='utf8') as f:\n","    for video_i in range(len(X_train)):\n","      f.write(f'\"video{video_i}\": {{\\n')\n","      for frame_i in range(len(X_train[video_i])):\n","        f.write(f'\\t\"frame{frame_i}\": {{\\n')\n","        for joint_i in range(len(X_train[video_i][frame_i])):\n","          f.write(f'\\t\\t\"joint{MIN_JOINT + joint_i}\": {{\\n')\n","          f.write(f'\\t\\t\\t\"polar\": {X_train[video_i][frame_i][joint_i][0]}, \\n')\n","          f.write(f'\\t\\t\\t\"velocity\": {X_train[video_i][frame_i][joint_i][1]}\\n')\n","          f.write(f'\\t\\t}}, \\n')\n","        f.write(f'\\t}}, \\n')\n","      f.write(f'}}, \\n')\n","  np.save(folder + 'train/X_train.npy', X_train, allow_pickle = True)\n","\n","  y_train_output_filename = folder + 'train/y_train.txt'\n","  with open(y_train_output_filename, 'w', encoding='utf8') as f:\n","    for video_i in range(len(y_train)):\n","      f.write(f'\"video{video_i}\": {y_train[video_i]}, \\n')\n","  np.save(folder + 'train/y_train.npy', y_train, allow_pickle = True)\n","\n","  X_test_output_filename = folder + 'test/X_test.txt'\n","  with open(X_test_output_filename, 'w', encoding='utf8') as f:\n","    for video_i in range(len(X_train)):\n","      f.write(f'\"video{video_i}\": {{\\n')\n","      for frame_i in range(len(X_train[video_i])):\n","        f.write(f'\\t\"frame{frame_i}\": {{\\n')\n","        for joint_i in range(len(X_train[video_i][frame_i])):\n","          f.write(f'\\t\\t\"joint{MIN_JOINT + joint_i}\": {{\\n')\n","          f.write(f'\\t\\t\\t\"polar\": {X_train[video_i][frame_i][joint_i][0]}, \\n')\n","          f.write(f'\\t\\t\\t\"velocity\": {X_train[video_i][frame_i][joint_i][1]}\\n')\n","          f.write(f'\\t\\t}}, \\n')\n","        f.write(f'\\t}}, \\n')\n","      f.write(f'}}, \\n')\n","  np.save(folder + 'test/X_test.npy', X_test, allow_pickle = True)\n","\n","  y_test_output_filename = './drive/My Drive/CS256Project/data/data_for_lstm/test/y_test.txt'\n","  with open(y_test_output_filename, 'w', encoding='utf8') as f:\n","    for video_i in range(len(y_train)):\n","      f.write(f'\"video{video_i}\": {y_train[video_i]}, \\n')\n","  np.save(folder + 'test/y_test.npy', y_train, allow_pickle = True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4VAg8f-qS7Gx"},"source":["# Evaluate model"]},{"cell_type":"code","metadata":{"id":"3CaVh9ARRrV5"},"source":["# fit and evaluate a model\n","def evaluate_model(trainX, trainy, testX, testy, neurons=50, drop_out_rate = 0.5, lstm_layers = 1, dropout_layers = 1, summary = True):\n","\tverbose, epochs, batch_size = 0, 15, 64\n","\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], 2\n","\tmodel = Sequential()\n","\tmodel.add(Masking(mask_value=MASK_VALUE, input_shape=(n_timesteps, n_features))) # Masking layer\n","\tfor _ in range(lstm_layers - 1):\n","\t\tmodel.add(LSTM(neurons, input_length=trainX.shape[1], input_dim=trainX.shape[2], return_sequences = True))\n","\tmodel.add(LSTM(neurons, input_length=trainX.shape[1], input_dim=trainX.shape[2]))\n"," \n","\tfor _ in range(dropout_layers):\n","\t\tmodel.add(Dropout(drop_out_rate))\n","\t\tmodel.add(Dense(100, activation='relu'))\n","\t\n","\tmodel.add(Dense(n_outputs, activation='softmax'))\n","\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  \n","\t# fit network\n","\tif(summary):\n","\t\tmodel.summary()\n","\ttrainy = to_categorical(trainy)\n","\ttesty = to_categorical(testy)\n","\tmodel.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n","\t# model.fit(trainX, trainy)\n","\t# evaluate model\n","\t_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=verbose)\n","\treturn accuracy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h6ovyCLdTCvX"},"source":["## Test out different hyper paramenter for training with polar angle"]},{"cell_type":"code","metadata":{"id":"1eYmRtxRGF_O"},"source":["# Clears backend keras session: https://stackoverflow.com/questions/55299510/cpu-usage-and-time-until-training-starts-increasing-on-each-model-fit-in-keras/55300684\n","backend.clear_session()\n","\n","print('+-----------+')\n","print('|Polar angle|')\n","print('+-----------+')\n","Polar_train, Polar_test = X_train[:, :, :, 0], X_test[:, :, :, 0]\n","plot_num_neurons, accuracy = [], []\n","for neurons in range(50, 1001, 50):\n","  plot_num_neurons.append(neurons)\n","  backend.clear_session()\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","\n","plt.subplot(1, 4, 1) # row 1, col 2 index 1\n","plt.plot(plot_num_neurons, accuracy)\n","plt.xlabel('Number of neurons')\n","plt.ylabel('Accuracy')\n","\n","\n","plot_dropout, accuracy = [], []\n","for dropout_rate in np.arange(0.0, 1.0, 0.1):\n","  plot_dropout.append(dropout_rate)\n","  backend.clear_session()\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = dropout_rate, lstm_layers= 1, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","\n","plt.subplot(1, 4, 2) # index 2\n","plt.plot(plot_dropout, accuracy)\n","plt.xlabel('Dropout rate')\n","\n","plot_LSTM, accuracy = [], []\n","for layers in np.arange(1, 6, 1):\n","  plot_LSTM.append(layers)\n","  backend.clear_session()\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","  \n","plt.subplot(1, 4, 3) # index 3\n","plt.plot(plot_LSTM, accuracy)\n","plt.xlabel('LSTM layers')\n","\n","plot_dropout_layer, accuracy = [], []\n","for layers in np.arange(1, 6, 1):\n","  plot_dropout_layer.append(layers)\n","  backend.clear_session()\n","  # %%time\n","  acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = 50, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = layers, summary = False)\n","  accuracy.append(acc)\n","\n","plt.subplot(1, 4, 4) # index 4\n","plt.plot(plot_dropout_layer, accuracy)\n","plt.xlabel('Dropout layers')\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GlQ_KXz1GO34"},"source":["# commit: 'Changing #layer and #neuron'\n","print('+-----------+')\n","print('|Polar angle|')\n","print('+-----------+')\n","Polar_train, Polar_test = X_train[:, :, :, 0], X_test[:, :, :, 0]\n","\n","\n","lstm = []\n","layer_gen = range(1, 11)\n","neuron_gen = range(50, 1001, 30)\n","for layers in layer_gen:\n","  row = []\n","  print(layers, end = '')\n","  for neurons in tqdm(neuron_gen):\n","    backend.clear_session()\n","    acc = evaluate_model(Polar_train, y_train, Polar_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n","    row.append(acc)\n","  lstm.append(row)\n","\n","plt.figure(figsize=(30, 10))\n","sns.heatmap(lstm, linewidth=0.5, xticklabels= [i for i in neuron_gen], yticklabels=[i for i in layer_gen], annot = True)\n","plt.xlabel('Neurons')\n","plt.ylabel('Layers')\n","plt.title('LSTM layer')\n","plt.savefig('./drive/My Drive/CS256Project/LSTM_layer_heatmap-20211114.png')\n","np.savetxt(\"./drive/My Drive/CS256Project/LSTM_layer-20211114.csv\", lstm, delimiter=\",\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IAIsIBR8TNVU"},"source":["## Test out different hyper paramenter for training with polar velocity"]},{"cell_type":"code","metadata":{"id":"bEmtiq8jGWsD"},"source":["backend.clear_session()\n","print('+--------+')\n","print('|Velocity|')\n","print('+--------+')\n","Velocity_train, Velocity_test = X_train[:, :, :, 1], X_test[:, :, :, 1]\n","plot_num_neurons, accuracy = [], []\n","for neurons in range(30, 110, 10):\n","  plot_num_neurons.append(neurons)\n","  backend.clear_session()\n","  acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = neurons, drop_out_rate = 0.5, lstm_layers= 1, dropout_layers = 1, summary = False)\n","  accuracy.append(acc)\n","  print('\\t{0} neurons have accuracy {1:.2f}'.format(neurons, acc))\n","\n","plt.subplot(1, 4, 1) # row 1, col 2 index 1\n","plt.plot(plot_num_neurons, accuracy)\n","plt.xlabel('Number of neurons')\n","plt.ylabel('Accuracy')\n","\n","# Goes with 40 neurons for now \n","# plot_LSTM, accuracy = [], []\n","# for layers in np.arange(1, 6, 1):\n","#   plot_LSTM.append(layers)\n","#   backend.clear_session()\n","#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = 0.5, lstm_layers= layers, dropout_layers = 1, summary = False)\n","#   accuracy.append(acc)\n","#   print('\\t{0} layers have accuracy {1:.2f}'.format(layers, acc))\n","\n","# plt.subplot(1, 4, 3) # index 3\n","# plt.plot(plot_LSTM, accuracy)\n","# plt.xlabel('LSTM layers')\n","\n","# plot_dropout_layer, accuracy = [], []\n","# for layers in np.arange(1, 6, 1):\n","#   plot_dropout_layer.append(layers)\n","#   backend.clear_session()\n","#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = 0.5, lstm_layers= 4, dropout_layers = layers, summary = False)\n","#   accuracy.append(acc)\n","#   print('\\t{0} dense layers have accuracy {1:.2f}'.format(layers, acc))\n","\n","# plt.subplot(1, 4, 4) # index 2\n","# plt.plot(plot_dropout_layer, accuracy)\n","# plt.xlabel('Dropout layers')\n","\n","# plot_dropout, accuracy = [], []\n","# for dropout_rate in np.arange(0.0, 1.1, 0.1):\n","#   plot_dropout.append(dropout_rate)\n","#   %%time\n","#   backend.clear_session()\n","#   acc = evaluate_model(Velocity_train, y_train, Velocity_test, y_test, neurons = 40, drop_out_rate = dropout_rate, lstm_layers= 4, dropout_layers = 1, summary = False)\n","#   accuracy.append(acc)\n","#   print('\\t{0} dropout rate have accuracy {1:.2f}'.format(dropout_rate, acc))\n","\n","\n","# plt.subplot(1, 4, 2) # index 2\n","# plt.plot(plot_dropout, accuracy)\n","# plt.xlabel('Dropout rate')\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qEHGKbG4TQIe"},"source":["## Test out different hyper paramenter for training with polar angle and velocity"]},{"cell_type":"code","metadata":{"id":"HLSgPzR1iarP"},"source":["backend.clear_session()\n","print('+-------------------+')\n","print('|Angle and Velocity|')\n","print('+-------------------+')\n","\n","both_trainX = np.concatenate((X_train[:, :, :, 0], X_train[:, :, :, 1]), axis=2)\n","both_testX = np.concatenate((X_test[:, :, :, 0], X_test[:, :, :, 1]), axis=2)\n","both_trainX.shape\n","\n","plot_neurons, acc_neurons = [], []\n","plot_layers, acc_layers = [], []\n","plot_dropout, acc_dropout = [], []\n","# ----------------------------------------------------------------\n","# Different number of neurons\n","# ----------------------------------------------------------------\n","for neurons in np.arange(50, 1001, 50):\n","  acc_neurons.append(evaluate_model(both_trainX, y_train, both_testX, y_test, neurons=neurons, summary=False))\n","  plot_neurons.append(neurons)\n","plt.subplot(1, 4, 1) # row 1, col 2 index 1\n","#plt.figure(figsize=(8,4))\n","plt.plot(plot_neurons, acc_neurons)\n","plt.xlabel('Number of neurons')\n","plt.ylabel('Accuracy')\n","\n","backend.clear_session()\n","\n","\n","# ----------------------------------------------------------------\n","# Different number LSTM layers\n","# ----------------------------------------------------------------\n","\n","for layers in np.arange(1, 6, 1):\n","  acc_layers.append(evaluate_model(both_trainX, y_train, both_testX, y_test, lstm_layers=layers, summary=False))\n","  plot_layers.append(layers)\n","plt.subplot(1, 4, 2) # row 1, col 2 index 2\n","#plt.figure(figsize=(8,4))\n","plt.plot(plot_layers, acc_layers)\n","plt.xlabel('Number of layers')\n","plt.ylabel('Accuracy')\n","\n","backend.clear_session()\n","\n","# ----------------------------------------------------------------\n","# Different Dropout\n","# ----------------------------------------------------------------\n","\n","for rate in np.arange(0.0, 1.0 , 0.2):\n","  acc_dropout.append(evaluate_model(both_trainX, y_train, both_testX, y_test, drop_out_rate=rate, summary=False))\n","  plot_dropout.append(rate)\n","\n","plt.subplot(1, 4, 3) # row 1, col 2 index 3\n","#plt.figure(figsize=(8,4))\n","plt.plot(plot_dropout, acc_dropout)\n","plt.xlabel('Dropout rate')\n","plt.ylabel('Accuracy')\n","\n","\n","plt.show()"],"execution_count":null,"outputs":[]}]}